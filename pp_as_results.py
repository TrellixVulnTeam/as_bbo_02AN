"""
Postprocessing results of algorithm selection.
"""
import numpy as np
import pandas as pd
import statistics as stat
import csv
import os
import sys
import logging
import click
# import random
import json
import shutil
from fopt_info import bbob_fopt

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.DEBUG)
#logging.basicConfig(filename='{}.log'.format(__file__), level=logging.DEBUG)

def pp_fevals_to_reach(fevals_file_path=None, fun_id=1, dim=2, instance_id=1, pre_res_arr=None, used_feval=0, alg=None):
    # targets = 10^2, ..., 10^-2
    targets = [10**i for i in np.arange(2, -2.1, -0.2)]
    # target_pows = 2, 1.8, ..., -7.8, -8
    target_pows = np.arange(2, -2.1, -0.2)
    target_pows = np.round(target_pows, 2)
    target_pows = target_pows.astype(str)
    target_pows = target_pows[::-1]

    # If the pre-solver reached the target value, algorithm selection is not performed
    if alg == None:
        with open(fevals_file_path, 'w') as fh:
            #fh.write("#target,the number of function evaluations to reach the target,0:the run was unsuccessful and 1:the run was successful\n")        
            for i, arr in enumerate(pre_res_arr[::-1]):
                fh.write("{},{},{}\n".format(target_pows[i], int(arr[1]), int(arr[2])))                 
    else:
        original_fevals_file_path = os.path.join('pp_bbob_exdata/fevals_to_reach', alg, 'f{}_DIM{}_i{}.csv'.format(fun_id, dim, instance_id))
        original_res_arr = np.loadtxt(original_fevals_file_path, delimiter=",", comments="#", dtype=float)
 
        pp_res_arr = np.zeros((len(targets), 2))
        
        for i, (target_, feval, success) in enumerate(original_res_arr[::-1]):
            if target_ < -2:
                break

            if int(pre_res_arr[i][2]) == 1 and pre_res_arr[i][1] < feval:
                pp_res_arr[i][0] = pre_res_arr[i][1]
                pp_res_arr[i][1] = 1
            else:
                pp_res_arr[i][0] = feval + used_feval
                pp_res_arr[i][1] = success

        with open(fevals_file_path, 'w') as fh:
            for i, arr in enumerate(pp_res_arr[::-1]):
                fh.write("{},{},{}\n".format(target_pows[i], int(arr[0]), int(arr[1])))                 

def pp_selected_algs(ap_dir_path, as_res_dir_path, sample_dir_path, bbob_suite, dim, fun_id, test_instance_ids, target_pow, pre_solver, per_metric='sp1'):
    pp_dir_path = 'pp_' + as_res_dir_path
    if pre_solver != None:
        pp_dir_path += '_' + pre_solver

    fevals_dir_path = os.path.join(pp_dir_path, 'fevals_to_reach')
    os.makedirs(fevals_dir_path, exist_ok=True)    
        
    # Read the best ERT value
    best_ert_file_path = os.path.join(ap_dir_path, 'ert', 'best_f{}_DIM{}_liid0.csv'.format(fun_id, dim))
    with open(best_ert_file_path, 'r') as fh:
        best_ert = float(fh.read())

    # Read the PAR10 value
    par10_file_path = os.path.join(ap_dir_path, 'relert', 'par10_DIM{}_liid0.csv'.format(dim))
    with open(par10_file_path, 'r') as fh:
        par10_ert_value = float(fh.read())

    # Read the best SP1 value
    best_sp1_file_path = os.path.join(ap_dir_path, 'sp1', 'best_f{}_DIM{}_liid0.csv'.format(fun_id, dim))
    with open(best_sp1_file_path, 'r') as fh:
        best_sp1 = float(fh.read())

    # Read the PAR10 value
    par10_file_path = os.path.join(ap_dir_path, 'relsp1', 'par10_DIM{}_liid0.csv'.format(dim))
    with open(par10_file_path, 'r') as fh:
        par10_sp1_value = float(fh.read())
        
    # Postprocess the performance of a sampler
    # "all_feval_list" maintains the number of function evaluations used until the termination of the search. It is for the ERT calculation
    all_feval_list = []
    # "success_feval_list" maintains the number of function evaluations only for successful runs. It is for the SP1 calculation
    succ_feval_list = []
    # The number of successful runs.
    n_success = 0
    for instance_id in test_instance_ids:        
        is_success, feval, res_arr = feval_sample(sample_dir_path, bbob_suite, dim, fun_id, instance_id, target_pow, pre_solver)        
        # When a solution with a target value is found in the sampling phase, there is no need to count the fevals for an algorithm portfolio.
        if is_success == True:
            logger.info('A solution generated by the pre-solving phase or the sampling phase reached the target value at %d function evaluations (fid=%d, iid=%d, dim=%d)', feval, fun_id, instance_id, dim)
            # 0 is appended to l_sample_fevals. The sum of l_sample_fevals and l_fevals is used for the ERT calculation later.
            all_feval_list.append(feval)
            succ_feval_list.append(feval)            
            n_success += 1

            fevals_file_path = os.path.join(fevals_dir_path, 'f{}_DIM{}_i{}.csv'.format(fun_id, dim, instance_id))            
            pp_fevals_to_reach(fevals_file_path=fevals_file_path, fun_id=fun_id, dim=dim, instance_id=instance_id, pre_res_arr=res_arr)
        else:
            # When a solution with a target value is NOT found in the sampling phase and the pre-solving phase, algorithm selection is performed
            pred_alg_file_path = os.path.join(as_res_dir_path, 'selected_alg_f{}_DIM{}_i{}.csv'.format(fun_id, dim, instance_id))
            with open(pred_alg_file_path, 'r') as fh:
                pred_alg = fh.read()
                
            fevals_file_path = os.path.join(ap_dir_path, 'fevals_to_reach', '{}_f{}_DIM{}_i{}.csv'.format(pred_alg, fun_id, dim, instance_id))
            solver_feval, is_success = np.loadtxt(fevals_file_path, delimiter=",", comments="#", dtype=float)

            if np.isnan(solver_feval):
                logger.error('The fevals_file_path contains the NaN value: %s', fevals_file_path)
                exit(1)
            else:
                # Please recall that the missing feval value was already imputed by the maximum number of function evaluations.
                all_feval_list.append(feval+solver_feval)                
                n_success += int(is_success)

                if int(is_success) == 1:
                    succ_feval_list.append(feval+solver_feval)                                                

            fevals_file_path = os.path.join(fevals_dir_path, 'f{}_DIM{}_i{}.csv'.format(fun_id, dim, instance_id))            
            pp_fevals_to_reach(fevals_file_path=fevals_file_path, fun_id=fun_id, dim=dim, instance_id=instance_id, pre_res_arr=res_arr, used_feval=feval, alg=pred_alg)
                        
    if n_success > 0:
        # ERT
        ert_value = sum(all_feval_list) / float(n_success)

        # SP1
        succ_prob = float(n_success) / len(test_instance_ids)
        sp1_value = stat.mean(succ_feval_list) / succ_prob                
        
        # NOTE: The present implementation assumes that a pre-solver cannot reach the target value when all the optimizers in an algorithm portfolio cannot reach the target value. However, the pre-solver CAN POSSIBLY reach the target value EVEN WHEN all the optimizers in an algorithm portfolio cannot reach the target value. In this case, it is unclear how to calculate the relERT value because the best ERT is not available.            
        if np.isnan(best_ert):
            logger.warning('The best ERT value is not available because all optimizers in the portfolio failed to reach the target value. The relERT value is imputed by PAR10. fid = %d, iid = %d, dim = %d', fun_id, instance_id, dim)
            rel_ert_value = par10_ert_value
            rel_sp1_value = par10_sp1_value
        else:
            rel_ert_value = ert_value / best_ert
            rel_sp1_value = sp1_value / best_sp1            
    else:
        rel_ert_value = par10_ert_value
        rel_sp1_value = par10_sp1_value
        # TODO: How can I impute the missing ERT (not relERT) value? An immediate solution may be that the missing ERT value is imputed by the PAR10 of the worst ERT value in an algorithm portfolio. However, this solution misleads the comparison of algorithm selection systems with different algorithm portfolios, e.g., one uses kt_ecj19, and another uses dlvat_foga19.
        ert_value = np.nan
        sp1_value = np.nan
        
    relert_dir_path = os.path.join(pp_dir_path, 'relert')
    os.makedirs(relert_dir_path, exist_ok=True)    
    relert_file_path = os.path.join(relert_dir_path, 'f{}_DIM{}_liid0.csv'.format(fun_id, dim))
    with open(relert_file_path, 'w') as fh:
        fh.write("{}".format(rel_ert_value))

    ert_dir_path = os.path.join(pp_dir_path, 'ert')        
    os.makedirs(ert_dir_path, exist_ok=True)
    ert_file_path = os.path.join(ert_dir_path, 'f{}_DIM{}_liid0.csv'.format(fun_id, dim))
    with open(ert_file_path, 'w') as fh:
        fh.write("{}".format(ert_value))
        
    relsp1_dir_path = os.path.join(pp_dir_path, 'relsp1')
    os.makedirs(relsp1_dir_path, exist_ok=True)    
    relsp1_file_path = os.path.join(relsp1_dir_path, 'f{}_DIM{}_liid0.csv'.format(fun_id, dim))
    with open(relsp1_file_path, 'w') as fh:
        fh.write("{}".format(rel_sp1_value))

    sp1_dir_path = os.path.join(pp_dir_path, 'sp1')        
    os.makedirs(sp1_dir_path, exist_ok=True)
    sp1_file_path = os.path.join(sp1_dir_path, 'f{}_DIM{}_liid0.csv'.format(fun_id, dim))
    with open(sp1_file_path, 'w') as fh:
        fh.write("{}".format(sp1_value))        

def feval_sample(sample_dir_path, bbob_suite, dim, fun_id, instance_id, target_pow, pre_solver):
    # targets = 10^2, ..., 10^-2
    targets = [10**i for i in np.arange(2, -2.1, -0.2)]
    # target_pows = 2, 1.8, ..., -7.8, -8
    target_pows = np.arange(2, -8.1, -0.2)
    target_pows = np.round(target_pows, 2)
    target_pows = target_pows.astype(str)

    target = 10**float(target_pow)

    if bbob_suite == 'bbob':    
        sample_data_file_path = os.path.join(sample_dir_path, 'x_f_data_{}_f{}_DIM{}_i{}.csv'.format(bbob_suite, fun_id, dim, instance_id))
        data_set = np.loadtxt(sample_data_file_path, delimiter=",", comments="#", dtype=float)
        # Only the objective values are enough. 
        sample_f = data_set[:, 0]

        # When using a pre-solver:
        if pre_solver != None:
            sid = sample_dir_path[sample_dir_path.find('sid')+3:]
            presolver_data_file_path = os.path.join('./presolver_data', '{}_sid{}'.format(pre_solver, sid), 'presolver_x_f_data_{}_f{}_DIM{}_i{}.csv'.format(bbob_suite, fun_id, dim, instance_id))
            if os.path.exists(presolver_data_file_path):
                ps_data_set = np.loadtxt(presolver_data_file_path, delimiter=",", comments="#", dtype=np.float)
                ps_sample_f = ps_data_set[:, 0]
                sample_f = np.concatenate([ps_sample_f, sample_f])
            else:
                logger.error('Not found: %s', presolver_data_file_path)
                exit(1)            
    elif bbob_suite == 'bbob-noisy':
        noiseless_obj_file_path = os.path.join(sample_dir_path, 'noiseless_f_data_{}_f{}_DIM{}_i{}.csv'.format(bbob_suite, fun_id, dim, instance_id))               
        sample_f = np.loadtxt(noiseless_obj_file_path, delimiter=",", comments="#", dtype=np.float)        

    # Read the objective value of the optimal solution f(x^*)
    fopt_file_path = os.path.join('./bbob_fopt_data', 'fopt_f{}_DIM{}_i{}.csv'.format(fun_id, dim, instance_id))
    with open(fopt_file_path, 'r') as fh:    
        fopt = float(fh.read())
        
    # Note: The objective value f(x) and the error value |f(x) - f(x^*)| should be distinguished
    sample_error_values = np.abs(sample_f - fopt)

    target_id = 0
    # res_arr[i][0] = the i-th target, res_arr[i][1] = fevals to reach the i-th target, res_arr[i][2] = success (1) or failure (0)
    res_arr = np.zeros((len(targets), 3))
    for feval, error in enumerate(sample_error_values, 1):
        # When |f(x) - f(x^*)| < the target value (e.g., 10^-2), it means that the pre-solver (or the sampler) reached the target value during the run.
        while error < targets[target_id]:
            res_arr[target_id][0] = target_pows[target_id]
            res_arr[target_id][1] = feval
            res_arr[target_id][2] = 1            
            target_id += 1
            if target_id >= len(targets):
                break
        if target_id >= len(targets):
            break
        
    for feval, error_value in enumerate(sample_error_values, 1):
        if error_value <= target:
            return True, feval, res_arr

    # The pre-solver could not reach the target value, where len(sample_f) is the number of function evaluations used in the sampling phase
    return False, len(sample_f), res_arr

# @click.command()
# @click.option('--as_res_dir_path', '-asdir', required=False, default='kt_ecj19', type=str, help='Path to the directory of results of an algorithm selection system')
# # @click.option('--dir_sampling_method', '-dsample', required=False, default='ihs_multiplier50_sid0', type=str, help='Directory of a sampling method.')
def run(as_res_dir_path, pre_solver=None, bbob_suite='bbob'):
    dims = [2, 3, 5, 10]
    #dims = [10]    
    test_instance_ids = range(1, 5+1)
    target_pow = '-2.0'

    all_fun_ids = range(1, 24+1)
    if bbob_suite == 'bbob-noisy':
        all_fun_ids = range(101, 130+1)    

    # The bbob_fopt_data directory contains a file that provides the objective value f(x^*) of the optimal solution x^* for each function instance. f(x^*) is used in the postprocessing the performance of a sampler    
    if os.path.exists('./{}_fopt_data'.format(bbob_suite)) == False:
        bbob_fopt()        

    as_config_file_path = os.path.join(as_res_dir_path, 'config.json')
    with open(as_config_file_path) as fh:
        config_dict = json.load(fh)

    # copy the relERT values of the SBS in the algorithm portfolio
    for dim in dims:
        pp_sbs_dir_path = 'pp_as_results/sbs_{}_{}_DIM{}/rel{}'.format(config_dict['ap_name'], config_dict['per_metric'], dim, config_dict['per_metric'])
        if os.path.isdir(pp_sbs_dir_path) == False:
            os.makedirs(pp_sbs_dir_path, exist_ok=True)                    
            sbs_file_path = os.path.join('./alg_portfolio', config_dict['ap_name'], 'sbs_{}/sbs_DIM{}.csv'.format(config_dict['per_metric'], dim))
            with open(sbs_file_path, 'r') as fh:
                sbs_name = fh.read()

            for fun_id in all_fun_ids:
                rel_metric_path = os.path.join('./alg_portfolio', config_dict['ap_name'], 'rel'+config_dict['per_metric'], '{}_f{}_DIM{}_liid0.csv'.format(sbs_name, fun_id, dim))
                copied_rel_metric_path = os.path.join(pp_sbs_dir_path, 'f{}_DIM{}_liid0.csv'.format(fun_id, dim))
                shutil.copyfile(rel_metric_path, copied_rel_metric_path)
                
    # Calculate the relERT value of the algorithms selected by the algorithm selection system
    for dim in dims:
        for fun_id in all_fun_ids:
            pp_selected_algs(config_dict['ap_dir_path'], as_res_dir_path, config_dict['sample_dir_path'], bbob_suite, dim, fun_id, test_instance_ids, target_pow, pre_solver, per_metric=config_dict['per_metric'])
        
if __name__ == '__main__':
    ela_feature_classes = 'basic_ela_distr_pca_limo_ic_disp_nbc_ela_level_ela_meta'
    dims = 'dims2_3_5_10'
    sampling_method = 'ihs'
    sample_multiplier = 50
    per_metric = 'sp1'
    feature_selector = 'none'
    n_features_to_select = 0
    
    for ap_name in ['kt', 'dlvat', 'jped', 'bmtp', 'mk', 'ls2', 'ls4', 'ls6', 'ls8', 'ls10', 'ls12', 'ls14', 'ls16', 'ls18']:
        for pre_solver in [None, 'slsqp_multiplier50', 'smac_multiplier50']:
            for sid in range(0, 31):
                dir_sampling_method = '{}_multiplier{}_sid{}'.format(sampling_method, sample_multiplier, sid)
                table_data_name = dir_sampling_method + '_' + per_metric + '_' + ela_feature_classes + '_' + dims
                for selector in ['multiclass_classification', 'hiearchical_regression', 'clustering', 'pairwise_regression', 'pairwise_classification']:
                    for cross_valid_type in ['loio_cv', 'lopo_cv', 'lopoad_cv']:
                        as_result_dir_path = os.path.join('as_results', '{}_{}_{}_{}_{}'.format(ap_name, selector, cross_valid_type, table_data_name, feature_selector))
                        if feature_selector != 'none':
                            as_result_dir_path += '_nfs{}'.format(n_features_to_select)    
                        run(as_result_dir_path, pre_solver=pre_solver)
                        logger.info("Postprocessing of %s was done.", as_result_dir_path)
